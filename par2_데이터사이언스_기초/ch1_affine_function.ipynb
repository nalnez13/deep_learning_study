{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Functions with 1 Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "===Input/Weight/Bias===\n",
      "x: (1, 1)/[[10.]]\n",
      "W: (1, 1)/[[-0.2556126]]\n",
      "B: (1,)/[[10.]]\n",
      "===Output===\n",
      "y TF: (1, 1) [[-2.556126]]\n",
      "y Manumal: (1, 1) [[-2.556126]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.constant([[10.]])\n",
    "print(x.shape)\n",
    "\n",
    "dense = Dense(units=1, activation='linear') # input의 shape 을 모르는 상태기 때문에 init이 안됨\n",
    "# W, B = dense.get_weights() 여기선 에러 발생!\n",
    "\n",
    "Y_tf = dense(x) # Forward propagation + param 초기화 발생\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B # Forward propagation(manual)\n",
    "\n",
    "print('===Input/Weight/Bias===')\n",
    "print(f'x: {x.shape}/{x.numpy()}')\n",
    "print(f'W: {W.shape}/{W}')\n",
    "print(f'B: {B.shape}/{x}')\n",
    "\n",
    "print('===Output===')\n",
    "print(f'y TF: {Y_tf.shape} {Y_tf.numpy()}')\n",
    "print(f'y Manumal: {y_man.shape} {y_man.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.initializers.initializers_v2.Constant object at 0x00000236C859C0A0> <tensorflow.python.keras.initializers.initializers_v2.Constant object at 0x00000236C859C070>\n",
      "W: (1, 1)/[[10.]]\n",
      "B: (1,)/[[10.]]\n",
      "tf.Tensor([[120.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "w, b = tf.constant(10.), tf.constant(20.)\n",
    "w_init, b_init = Constant(w), Constant(b)\n",
    "print(w_init, b_init)\n",
    "\n",
    "# initialize\n",
    "dense = Dense(units=1,\n",
    "            activation='linear',\n",
    "            kernel_initializer=w_init,\n",
    "            bias_initializer=b_init)\n",
    "\n",
    "x = tf.constant([[10.]])\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "# result\n",
    "print(f'W: {W.shape}/{W}')\n",
    "print(f'B: {B.shape}/{x}')\n",
    "print(y_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Functions with n Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) tf.Tensor(\n",
      "[[7.310574   8.756303   7.284135   0.73001266 5.1256123  7.1595583\n",
      "  1.0547972  0.8894384  3.8202906  5.63066   ]], shape=(1, 10), dtype=float32)\n",
      "tf.Tensor([[-4.03018]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-4.03018]], shape=(1, 1), dtype=float32)\n",
      "(10, 1) [[-0.32732445]\n",
      " [-0.5919069 ]\n",
      " [-0.04982662]\n",
      " [ 0.6631437 ]\n",
      " [-0.20929849]\n",
      " [ 0.47903138]\n",
      " [-0.33477366]\n",
      " [ 0.34889752]\n",
      " [-0.01416683]\n",
      " [ 0.20682347]]\n",
      "(1,) [0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.random.uniform(shape=(1, 10), minval=0, maxval=10)\n",
    "print(x.shape, x)\n",
    "\n",
    "dense = Dense(units=1)\n",
    "y_tf = dense(x)\n",
    "w, b = dense.get_weights()\n",
    "y_man = tf.linalg.matmul(x, w)\n",
    "\n",
    "print(y_tf)\n",
    "print(y_man)\n",
    "print(w.shape, w)\n",
    "print(b.shape, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1, 5)\n",
      "[[ 0.30315638  0.6130659   1.1631515   0.44874308 -0.15970373]]\n",
      "Sigmoid(TF): [[0.5752139  0.6486399  0.7619049  0.61034036 0.46015868]]\n",
      "(1, 5)\n",
      "Sigmoid(manual): [[0.5752139  0.6486399  0.7619049  0.61034036 0.46015868]]\n",
      "(1, 5)\n",
      "Tanh(TF): [[ 0.29419845  0.5462817   0.82206434  0.42086527 -0.15835966]]\n",
      "(1, 5)\n",
      "Tanh(manual): [[ 0.29419845  0.5462817   0.8220643   0.42086524 -0.15835968]]\n",
      "(1, 5)\n",
      "ReLU(TF): [[0.30315638 0.6130659  1.1631515  0.44874308 0.        ]]\n",
      "(1, 5)\n",
      "ReLU(manual): [[0.30315638 0.6130659  1.1631515  0.44874308 0.        ]]\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import exp, maximum\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "x = tf.random.normal(shape=(1, 5))\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "# forward propagation(tf)\n",
    "y_sigmoid_tf = sigmoid(x)\n",
    "y_tanh_tf = tanh(x)\n",
    "y_relu_tf = relu(x)\n",
    "\n",
    "# forward propagation(manual)\n",
    "y_sigmoid_man = 1 / (1 + exp(-x))\n",
    "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "y_relu_man = maximum(x, 0)\n",
    "\n",
    "print(f'x: {x.shape}\\n{x}')\n",
    "print(f'Sigmoid(TF): {y_sigmoid_tf}\\n{y_sigmoid_tf.shape}')\n",
    "print(f'Sigmoid(manual): {y_sigmoid_man}\\n{y_sigmoid_man.shape}')\n",
    "\n",
    "print(f'Tanh(TF): {y_tanh_tf}\\n{y_tanh_tf.shape}')\n",
    "print(f'Tanh(manual): {y_tanh_man}\\n{y_tanh_man.shape}')\n",
    "\n",
    "print(f'ReLU(TF): {y_relu_tf}\\n{y_relu_tf.shape}')\n",
    "print(f'ReLU(manual): {y_relu_man}\\n{y_relu_man.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation in Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN with Sigmoid (1, 1)\n",
      "[[0.5059813]]\n",
      "AN with Tanh (1, 1)\n",
      "[[-0.98368865]]\n",
      "AN with ReLU (1, 1)\n",
      "[[0.78368676]]\n",
      "==========\n",
      "atviation manual forward : (1, 1)\n",
      "[[0.5059813]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import exp, maximum\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.random.normal(shape=(1, 5)) \n",
    "\n",
    "dense_sigmoid = Dense(units=1, activation='sigmoid')\n",
    "dense_tanh = Dense(units=1, activation='tanh')\n",
    "dense_relu = Dense(units=1, activation='relu')\n",
    "\n",
    "# forward propagtaion\n",
    "y_sigmoid = dense_sigmoid(x)\n",
    "y_tanh = dense_tanh(x)\n",
    "y_relu = dense_relu(x)\n",
    "\n",
    "print(f'AN with Sigmoid {y_sigmoid.shape}\\n{y_sigmoid}')\n",
    "print(f'AN with Tanh {y_tanh.shape}\\n{y_tanh}')\n",
    "print(f'AN with ReLU {y_relu.shape}\\n{y_relu}')\n",
    "\n",
    "print('==========')\n",
    "w, b = dense_sigmoid.get_weights()\n",
    "z = tf.linalg.matmul(x, w) + b\n",
    "a = 1 / (1 + exp(-z))\n",
    "print(f'atviation manual forward : {a.shape}\\n{a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation : sigmoid\n",
      "y_tf: (1, 1)\n",
      "[[0.5110764]]\n",
      "y_man: (1, 1)\n",
      "[[0.5110764]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.math import exp, maximum\n",
    "\n",
    "activation = 'sigmoid'\n",
    "\n",
    "x = tf.random.uniform(shape=(1, 10))\n",
    "\n",
    "dense = Dense(units=1, activation=activation)\n",
    "\n",
    "y_tf = dense(x)\n",
    "w, b = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, w) + b\n",
    "\n",
    "if activation == 'sigmoid':\n",
    "    y_man = 1 / (1 + exp(-y_man))\n",
    "elif activation == 'tanh':\n",
    "    y_man = (exp(y_man) - exp(-y_man)) / (exp(y_man) + exp(-y_man))\n",
    "elif activation == 'relu':\n",
    "    y_man = maximum(y_man, 0)\n",
    "\n",
    "print(\"Activation :\", activation)\n",
    "print(f'y_tf: {y_tf.shape}\\n{y_tf}')\n",
    "print(f'y_man: {y_man.shape}\\n{y_man}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x : (8, 10)\n",
      "Shape of W : (10, 1)\n",
      "Shape of N : (1,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_features = 8, 10\n",
    "x = tf.random.normal(shape=(N, n_features))\n",
    "\n",
    "dense = Dense(units=1, activation='relu')\n",
    "y = dense(x)\n",
    "w, b = dense.get_weights()\n",
    "print(f'Shape of x : {x.shape}')\n",
    "print(f'Shape of W : {w.shape}')\n",
    "print(f'Shape of N : {b.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of TF: \n",
      " [[0.20659985]\n",
      " [0.94612145]\n",
      " [0.07187063]\n",
      " [0.80417866]\n",
      " [0.9185698 ]\n",
      " [0.19960007]\n",
      " [0.39711988]\n",
      " [0.09214338]]\n",
      "Output of Manual: \n",
      " [[0.20659985]\n",
      " [0.94612145]\n",
      " [0.07187063]\n",
      " [0.80417866]\n",
      " [0.9185698 ]\n",
      " [0.19960007]\n",
      " [0.39711988]\n",
      " [0.09214338]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_features = 8, 10\n",
    "x = tf.random.normal(shape=(N, n_features))\n",
    "\n",
    "dense = Dense(units=1, activation='sigmoid')\n",
    "y_tf = dense(x)\n",
    "\n",
    "w, b = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, w) + b\n",
    "y_man = 1 / (1 + tf.math.exp(-y_man))\n",
    "\n",
    "print(f'Output of TF: \\n {y_tf}')\n",
    "print(f'Output of Manual: \\n {y_man}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "545900e352d047268087df7c6c99837ed2b248b42106cf6defd55828819bdd50"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
